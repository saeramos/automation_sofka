# Automation Sofka - Reto TÃ©cnico QA Full Automation

Proyecto completo de automatizaciÃ³n de pruebas que cubre UI (E2E), API, Performance y CI/CD, desarrollado con SerenityBDD, Screenplay Pattern, Gradle y JMeter.

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
- [TecnologÃ­as Utilizadas](#tecnologÃ­as-utilizadas)
- [Prerrequisitos](#prerrequisitos)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [EjecuciÃ³n de Pruebas](#ejecuciÃ³n-de-pruebas)
- [Reportes](#reportes)
- [IntegraciÃ³n con BrowserStack](#integraciÃ³n-con-browserstack)
- [CI/CD Pipeline](#cicd-pipeline)
- [Entregables](#entregables)

## ğŸ“ DescripciÃ³n del Proyecto

Este proyecto implementa un framework completo de automatizaciÃ³n de pruebas que incluye:

1. **AutomatizaciÃ³n E2E (UI)**: Flujo completo de "Contact Us" con carga de archivos
2. **Pruebas de API**: ValidaciÃ³n del ciclo de vida de recursos (POST y GET)
3. **Pruebas de Performance**: Pruebas de carga con JMeter (50 VUs, 5 minutos)
4. **CI/CD**: Pipeline automatizado con GitHub Actions

## ğŸ›  TecnologÃ­as Utilizadas

- **Java 17**: Lenguaje de programaciÃ³n
- **Gradle 8.x**: Gestor de dependencias y construcciÃ³n
- **SerenityBDD 4.0.30**: Framework de automatizaciÃ³n y reportes
- **Screenplay Pattern**: PatrÃ³n de diseÃ±o para pruebas
- **JUnit 5**: Framework de testing
- **RestAssured**: LibrerÃ­a para pruebas de API
- **JMeter 5.6.2**: Herramienta de pruebas de performance
- **Selenium WebDriver**: AutomatizaciÃ³n de navegadores
- **BrowserStack**: Plataforma de testing en la nube
- **GitHub Actions**: CI/CD

## ğŸ“¦ Prerrequisitos

Antes de ejecutar el proyecto, asegÃºrate de tener instalado:

- **Java JDK 17** o superior
  ```bash
  java -version
  ```

- **Gradle 8.x** (opcional, el proyecto incluye Gradle Wrapper)
  ```bash
  gradle -v
  ```

- **ChromeDriver** (se descarga automÃ¡ticamente con Serenity)
  - O configurar ChromeDriver en el PATH

- **JMeter 5.6.2** (para pruebas de performance)
  - Descargar desde: https://jmeter.apache.org/download_jmeter.cgi
  - Configurar variable de entorno `JMETER_HOME` (opcional)

- **Git** para clonar el repositorio

### Credenciales de BrowserStack (Opcional)

Para ejecutar pruebas en BrowserStack, configura las siguientes variables de entorno:

```bash
export BROWSERSTACK_USERNAME=tu_usuario
export BROWSERSTACK_ACCESS_KEY=tu_access_key
```

O en Windows:
```cmd
set BROWSERSTACK_USERNAME=tu_usuario
set BROWSERSTACK_ACCESS_KEY=tu_access_key
```

## ğŸš€ InstalaciÃ³n

1. **Clonar el repositorio**
   ```bash
   git clone <url-del-repositorio>
   cd automation_sofka
   ```

2. **Verificar Java**
   ```bash
   java -version
   ```

3. **Dar permisos de ejecuciÃ³n al wrapper de Gradle** (Linux/Mac)
   ```bash
   chmod +x gradlew
   ```

4. **Construir el proyecto**
   ```bash
   ./gradlew build
   ```
   
   En Windows:
   ```cmd
   gradlew.bat build
   ```

## ğŸ“ Estructura del Proyecto

```
automation_sofka/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml              # Pipeline de CI/CD
â”œâ”€â”€ jmeter/
â”‚   â””â”€â”€ performance-test.jmx       # Plan de pruebas de JMeter
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run-performance-test.sh    # Script para ejecutar pruebas de performance (Linux/Mac)
â”‚   â”œâ”€â”€ run-performance-test.bat   # Script para ejecutar pruebas de performance (Windows)
â”‚   â””â”€â”€ generate-performance-report.ps1  # Generador de reportes de performance
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â””â”€â”€ java/
â”‚   â”‚       â””â”€â”€ com/
â”‚   â”‚           â””â”€â”€ automation/
â”‚   â”‚               â”œâ”€â”€ models/           # Modelos de datos
â”‚   â”‚               â”œâ”€â”€ tasks/            # Tareas del patrÃ³n Screenplay
â”‚   â”‚               â”œâ”€â”€ userinterfaces/   # Page Objects
â”‚   â”‚               â”œâ”€â”€ questions/        # Questions del patrÃ³n Screenplay
â”‚   â”‚               â””â”€â”€ utils/            # Utilidades y configuraciones
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ java/
â”‚       â”‚   â””â”€â”€ com/
â”‚       â”‚       â””â”€â”€ automation/
â”‚       â”‚           â””â”€â”€ runners/          # Runners de pruebas
â”‚       â””â”€â”€ resources/
â”‚           â”œâ”€â”€ serenity.conf             # ConfiguraciÃ³n de Serenity
â”‚           â””â”€â”€ testdata/                 # Datos de prueba
â”œâ”€â”€ build.gradle                         # ConfiguraciÃ³n de Gradle
â”œâ”€â”€ settings.gradle                      # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ gradle.properties                    # Propiedades de Gradle
â””â”€â”€ README.md                            # Este archivo
```

## â–¶ï¸ EjecuciÃ³n de Pruebas

### Pruebas UI (E2E)

Ejecutar todas las pruebas UI:
```bash
./gradlew test --tests "com.automation.runners.ContactUsTest"
```

Generar reportes de Serenity:
```bash
./gradlew aggregate
```

Los reportes se generarÃ¡n en: `target/site/serenity/index.html`

### Pruebas de API

Ejecutar pruebas de API:
```bash
./gradlew test --tests "com.automation.runners.ApiTest"
```

### Pruebas de Performance

#### OpciÃ³n 1: Usando JMeter directamente

**Linux/Mac:**
```bash
export JMETER_HOME=/ruta/a/jmeter
./scripts/run-performance-test.sh
```

**Windows:**
```cmd
set JMETER_HOME=C:\apache-jmeter-5.6.2
scripts\run-performance-test.bat
```

#### OpciÃ³n 2: Ejecutar manualmente

```bash
$JMETER_HOME/bin/jmeter -n -t jmeter/performance-test.jmx -l jmeter-results/performance_test.jtl -e -o jmeter-results/report
```

Los resultados se guardarÃ¡n en:
- `jmeter-results/performance_test.jtl` (resultados en formato JTL)
- `jmeter-results/report/` (reporte HTML)

### Ejecutar todas las pruebas

```bash
./gradlew test
./gradlew aggregate
```

## ğŸ“Š Reportes

### Reportes de Serenity

DespuÃ©s de ejecutar las pruebas, los reportes se generan automÃ¡ticamente:

```bash
./gradlew aggregate
```

Abrir el reporte:
```bash
open target/site/serenity/index.html
```

O en Windows:
```cmd
start target\site\serenity\index.html
```

### Reportes de Bugs

Si se encuentran bugs durante la ejecuciÃ³n, se generarÃ¡ automÃ¡ticamente un reporte en:

```
reports/bugs/bug-report-YYYYMMDD-HHMMSS.html
```

### Reportes de Performance

Los reportes de performance se generan en:

```
jmeter-results/report/index.html
```

## ğŸŒ IntegraciÃ³n con BrowserStack

Para ejecutar pruebas en BrowserStack:

1. **Configurar credenciales** (variables de entorno o en serenity.conf):
   ```bash
   export BROWSERSTACK_USERNAME=tu_usuario
   export BROWSERSTACK_ACCESS_KEY=tu_access_key
   ```

2. **Ejecutar pruebas**:
   ```bash
   ./gradlew test --tests "com.automation.runners.ContactUsTest"
   ```

Las pruebas se ejecutarÃ¡n automÃ¡ticamente en BrowserStack si las credenciales estÃ¡n configuradas. De lo contrario, se ejecutarÃ¡n localmente.

### ConfiguraciÃ³n en serenity.conf

El archivo `src/test/resources/serenity.conf` incluye la configuraciÃ³n para BrowserStack. Puedes modificar los capabilities segÃºn tus necesidades.

## ğŸ”„ CI/CD Pipeline

El pipeline de CI/CD estÃ¡ configurado en `.github/workflows/ci-cd.yml` y se ejecuta automÃ¡ticamente en:

- Push a las ramas `main`, `master` o `develop`
- Pull requests a las ramas `main`, `master` o `develop`

### Jobs del Pipeline

1. **UI Tests**: Ejecuta las pruebas E2E y genera reportes
2. **API Tests**: Ejecuta las pruebas de API
3. **Performance Tests**: Ejecuta las pruebas de performance con JMeter
4. **Build Summary**: Genera un resumen de la ejecuciÃ³n

### Configurar Secrets en GitHub

Para usar BrowserStack en el pipeline, configura los siguientes secrets en GitHub:

1. Ve a Settings â†’ Secrets and variables â†’ Actions
2. Agrega:
   - `BROWSERSTACK_USERNAME`
   - `BROWSERSTACK_ACCESS_KEY`

### Ver Reportes en GitHub Actions

DespuÃ©s de cada ejecuciÃ³n del pipeline, los reportes estÃ¡n disponibles como artifacts:

1. Ve a la pestaÃ±a "Actions" en GitHub
2. Selecciona el workflow ejecutado
3. Descarga los artifacts:
   - `serenity-reports`: Reportes de Serenity
   - `bug-reports`: Reportes de bugs encontrados
   - `performance-test-results`: Resultados de performance
   - `execution-summary`: Resumen de la ejecuciÃ³n

## ğŸ“¦ Entregables

El proyecto incluye todos los entregables requeridos:

### 1. 
- La ejecuciÃ³n del pipeline en GitHub Actions
- La ejecuciÃ³n de pruebas en BrowserStack (si estÃ¡ configurado)
- La ejecuciÃ³n de pruebas de performance

### 2. Reporte de EjecuciÃ³n

Los reportes se generan en:
- **Serenity**: `target/site/serenity/`
- **Performance**: `jmeter-results/report/`
- **Bugs**: `reports/bugs/`

### 3. Proyecto Empaquetado

Para empaquetar el proyecto:

```bash
zip -r automation_sofka.zip . -x "*.git*" -x "*.idea*" -x "*target*" -x "*.gradle*"
```

O en Windows, usar un compresor como 7-Zip o WinRAR.

### 4. Reporte de Bugs

Si se encuentran bugs, el reporte se genera automÃ¡ticamente en `reports/bugs/`.

## ğŸ”§ ConfiguraciÃ³n Adicional

### Modificar URLs

Las URLs se configuran en `src/main/java/com/automation/utils/Constants.java`:

```java
public static final String BASE_URL = "https://automationexercise.com";
public static final String API_BASE_URL = "https://reqres.in/api";
```

### Modificar ConfiguraciÃ³n de Serenity

Edita `src/test/resources/serenity.conf` para modificar:
- ConfiguraciÃ³n del navegador
- Timeouts
- ConfiguraciÃ³n de BrowserStack
- Entornos

### Modificar Pruebas de Performance

Edita `jmeter/performance-test.jmx` para modificar:
- NÃºmero de usuarios virtuales
- DuraciÃ³n de la prueba
- Ramp-up time
- Endpoints a probar

## ğŸ› SoluciÃ³n de Problemas

### Error: ChromeDriver no encontrado

Serenity descarga automÃ¡ticamente ChromeDriver. Si hay problemas:
```bash
./gradlew clean
./gradlew build
```

### Error: No se pueden ejecutar pruebas en BrowserStack

Verifica que las credenciales estÃ©n configuradas correctamente:
```bash
echo $BROWSERSTACK_USERNAME
echo $BROWSERSTACK_ACCESS_KEY
```

### Error: JMeter no encontrado

Configura la variable de entorno:
```bash
export JMETER_HOME=/ruta/a/jmeter
```

O instala JMeter y actualiza la ruta en los scripts.

## ğŸ“ Notas Importantes

- Las pruebas UI requieren conexiÃ³n a Internet
- Las pruebas de API usan el servicio pÃºblico `reqres.in`
- Las pruebas de performance pueden tardar varios minutos
- Los reportes de Serenity se generan despuÃ©s de ejecutar `./gradlew aggregate`

## ğŸ‘¤ Autor

Desarrollado como parte del Reto TÃ©cnico QA - Automation Sofka

## ğŸ“„ Licencia

Este proyecto es de uso educativo y para demostraciÃ³n de habilidades tÃ©cnicas.

---


